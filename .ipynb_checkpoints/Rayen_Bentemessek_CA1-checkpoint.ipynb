{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cad89abd-d98c-48ff-8ccd-7d9bec1308e0",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"https://moodle.cct.ie/pluginfile.php/1/theme_catawesome/logo/1742974865/logo.png\" alt=\"Logo\" width=\"500\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d31f73-e8b5-4a08-ac8a-139aa7b11c17",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h2>ML_CA1_V6 </h2>\n",
    "    <h3> Machine Learning for AI</h3>\n",
    "    <h3>Name: Rayen Bentemessek</h3>\n",
    "    <h3>Student Numbers: 2021378 </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad2cbe1-8791-4e57-8b13-b4ff07669d66",
   "metadata": {},
   "source": [
    "# Spam Classification \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2ff80b-f915-4cf9-8a8f-76e0254fba44",
   "metadata": {},
   "source": [
    "\n",
    "This notebook walks through the complete process of building a machine learning model to classify spam emails using the `spambase_v6.csv` dataset. The analysis is structured around the following key steps:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Exploratory Data Analysis & Data Preparation (Combined)\n",
    "- Dataset inspection and null value handling\n",
    "- Class distribution analysis (spam vs. not spam)\n",
    "- Correlation overview  \n",
    "- Outlier detection and scaling effects\n",
    "\n",
    "\n",
    "EDA and data preparation were combined, I was preparing the data as I explore it.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Modeling & Evaluation\n",
    "- **K-Nearest Neighbors (KNN):** tested with multiple scaling, transformation and tuning strategies\n",
    "- **Multinomial Naive Bayes:** handled with different splitting methods, log transformation and MinMax scaling\n",
    "- **Random Forest:** tested default and tuned variants with and without stratified split\n",
    "\n",
    "Each model was evaluated using:\n",
    "-  Huge focus was given to **False Negatives (FN)** and **False Positives (FP)**, due to their importance on spam classification:\n",
    "    - *False negatives (missed spam)*\n",
    "    - *False positives (Classifying non spam emails as spam)* \n",
    "- Confusion matrices\n",
    "- Classification Report: **Accuracy**, **Precision**, **Recall**, and **F1-score** \n",
    "- summary comparison table for all model variants (for the positive -spam- class)\n",
    "---\n",
    "\n",
    "## 3. Final Classification Summary\n",
    "- Discussion of the best-performing model\n",
    "- Confusion matrix comparison across top models\n",
    "- Justification for model selection\n",
    "\n",
    "## 4. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a440015-0f79-4d52-98dc-421264ebacf5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Exploratory Data Analysis & Data Preparation (Combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8957805-0750-4b06-a071-0831a9989a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c57370-e98f-4b0b-ba01-268c266f92cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spambase_v6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2acc1a3-0fb1-46ac-aeb8-6489d172e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a88e87-7523-4eb9-8a79-2f60479c6c23",
   "metadata": {},
   "source": [
    "I noticed that some columns have null values, and some columns were not numerical\n",
    "So I extracted these columns to inspect them\n",
    "I noticed that some of them had values like 'zero', '?', 'none' and some were empty, so I changed the column data type to numeric and the undesired values to null values.\n",
    "The dataset was not big in size and ratio of these null values was very low (max %5) so I chose to keep them and change these NA's to 0's.\n",
    "Also, I had a column 'Unnamed: 0' that is not relevant our project, so I dropped it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d2323-4c4e-4a5e-a997-673640f6f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1263bf92-1c82-42c9-afbe-8a884f1ed33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracted columns with object data type to inspect them\n",
    "columns_to_change = df.select_dtypes(exclude=['float64','int64','bool'])\n",
    "columns_to_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d8e536-cfea-4b22-9208-3a5d95e3cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store invalid (non-numeric) values\n",
    "invalid = {}\n",
    "\n",
    "for col in columns_to_change:\n",
    "    # Convert entire column to string, then check which values fail numeric conversion\n",
    "    mask = pd.to_numeric(df[col].astype(str), errors='coerce').isna()\n",
    "    \n",
    "    # Extract unique values that failed (excluding actual NaNs)\n",
    "    unique_invalid = df.loc[mask, col].dropna().unique()\n",
    "    \n",
    "    if len(unique_invalid) > 0:\n",
    "        invalid[col] = unique_invalid\n",
    "\n",
    "# Print the invalid values found\n",
    "for col, values in invalid.items():\n",
    "    print(f\"Invalid values in {col}: {values}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820cdebc-3f54-48e0-96bc-d9732cd9957a",
   "metadata": {},
   "source": [
    "We notice that we have few invalid values, like zero, ?, none and no in addition to null values.\n",
    "That is why I will be changing all these these values to 0's as it is the one that makes more sense in this compared to other imputation techniques such as mean or median.\n",
    "Before that, we need to change these values to numeric, we will use coerce for the invalid parsing to be NaN. so those values will become NaNs first, and I will impute them with 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f7c816-4cee-4187-8e94-a428564c012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed the columns types to float, values like (zero, ???, None) will become null values\n",
    "columns_to_change = columns_to_change.columns.tolist()\n",
    "df[columns_to_change] = df[columns_to_change].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5416a-4e97-44fa-a9e7-fa8a18dcaf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of null values within the dataframe\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2430394-4b78-4cc6-9c91-d9430c689f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null values with 0's\n",
    "df = df.fillna(0)\n",
    "# dropped first column as it is not relevant\n",
    "df = df.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfa25f0-75b6-4132-be3c-4804bdd4379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1ba1b4-be71-4107-b786-6f5cd98fd01c",
   "metadata": {},
   "source": [
    "The previous preparation cells were necessary in order to visualise our data, and even to implement the model as we can not proceed with missing or unwanted values, so that had to be prioritised at first.\n",
    "\n",
    "In the next few lines, we will explore our data with different vizualisations that will give us few insights and more information about the overall structure, which will be so helpful in building a good model.\n",
    "\n",
    "The first finding I noticed, is that we have a large number of features, leading to a highly dimensional dataset, 57 features would definitely affect the performance of the model we will choose and this needs to be taken care of before the modelling stage. Later on, just below the correlation matrix, I will be discussing what am I going to do regarding this high dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5372f866-21c8-41fa-8efd-07c712857c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_spam'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf51ac5f-f71a-4e5a-9be9-2dd21975ecdc",
   "metadata": {},
   "source": [
    "From the distribution of our emails, 2788 non-spam (60.6%) vs. 1813 spam emails (39.4%), we notice a very slight imbalance.\n",
    "While imbalance can affect building a classification model, it is not a major problem in our case, however I would consider including a decision-tree based algorithm as they perform slightly better with imbalanced variables. \n",
    "Again, this is not a major issue and 60/40 is generally acceptable, so we wouldn't be going towards resampling techniques like Synthetic Minority Oversampling Technique (SMOTE), but there is no harm in choosing an algorithm known to have better handling of imbalanced data even if it's slight (mmalinda, 2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c5bfec-022d-409b-b50a-fae4faaf052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Distrbution of spam and non spam emails\n",
    "plt.figure(figsize=(10,5))\n",
    "counts = df['is_spam'].value_counts()\n",
    "plt.pie(counts, labels=['Non-spam','Spam'],autopct='%1.1f%%')\n",
    "plt.title(\"Distribution Emails\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37015def-da04-4e97-a88e-c12bc72566ca",
   "metadata": {},
   "source": [
    "I implemented the correlation matrix and heatmap to see if there's any correlations between our target variable 'is_spam' and any other variables.\n",
    "There was not any strong correlations and the stronget we could get was 0.38 with the word 'your' and that doesn't really tell us anything.\n",
    "So I decided to extract the top 10 correlated features (as the correlation heatmap was huge with 58 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded87880-26dd-43ae-865a-0df6ae76a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cormat = df.corr()\n",
    "round(cormat,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0845c87a-ba3c-43a2-9b33-3a217477a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation heatmap\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(cormat);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bb610b-f6b5-4740-bd07-9da5ee102400",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the top 10 correlations\n",
    "cormat_unstacked = cormat.abs().unstack().sort_values(ascending=False)\n",
    "cormat_unstacked = cormat_unstacked[cormat_unstacked < 1]\n",
    "top_10_correlations = cormat_unstacked.drop_duplicates().head(10)\n",
    "print(top_10_correlations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b871cc-b2a3-49d4-9241-0f964a02b505",
   "metadata": {},
   "source": [
    "I decided to go further with these correlated features, and I took 2 of highest correlations (word_freq_415 vs word_freq_857) and (word_freq_857 vs word_freq_direct) and visualized them in a histogram, and the data points were labeled by the spam labels, the results were quite interesting.\n",
    "The 2 histograms show us -apart from the highly positive correlation that we alreadt know-, that whenever the words 415/857 and 857/direct happen to be together in an email, that email is a spam message. This doesn't mean whenever 415 is frquent that is a spam email, correlation doesn't mean causation, but it's something that needs to be taken into consideration while implementing the model, as some algorithms would struggle more with this mulitcollinearity.\n",
    "\n",
    "This extremely high correlation between some variables can indeed affect the performance of the model chosen. While Decision Trees algorithm are not  affected in terms of accuracy (they are affected in terms of computation but in our case we don't have a large dataset to worry about that). This finding will actually add on the previous finding of the slight imbalance, in addition to the high dimensionality, in choosing a tree based algorithm (Decision Tree, Random Forest) as they would perform much better within these circumstances.\n",
    "However, since I'm not only going to choose decision tree algorithms, We need to pay attention to this Multicollinearity, and one of the methods to do so is Principal Component Analysis (PCA), that will aim to reduce the number of features, keeping only the most important ones, which will lead to reducing the most correlated features by keeping the most important information with the least number of features. Another method is to remove one of the features, but I won't be doing it because each data is different, I would have done if my columns were GDP and GDP per capita, where there is a mathematical operation that links them together, but the words 415 and 857 don't have any real relationship, so I'm keeping both. (Mustafa Erboga, 2024). It is important to mention that some features like capital_run_length_average, capital_run_length_average and capital_run_length_total are mathematically linked, but they don't have a strong correlation (0.49) so I'm keeping them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ad7e3-ee84-43e5-90f9-bf117a0da231",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subplots of 2 of the most correlated features by spam label\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))  \n",
    "\n",
    "sns.scatterplot(\n",
    "    x=df['word_freq_415'],  \n",
    "    y=df['word_freq_857'],\n",
    "    hue=df['is_spam'],\n",
    "    alpha=0.6, \n",
    "    ax=axes[0]\n",
    ")\n",
    "\n",
    "axes[0].grid(True, linestyle='-', linewidth=0.5)\n",
    "axes[0].set_xlabel(\"Frequency of the word 415\")\n",
    "axes[0].set_ylabel(\"Frequency of the word 857\")\n",
    "axes[0].set_title('Relationship between the frequencies of the words \"415\" and \"857\" by Spam label')\n",
    "axes[0].legend(title='Spam Label', labels=['Not Spam', 'Spam'])\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=df['word_freq_direct'],  \n",
    "    y=df['word_freq_857'],\n",
    "    hue=df['is_spam'],\n",
    "    alpha=0.6,\n",
    "    ax=axes[1]\n",
    "\n",
    ")\n",
    "\n",
    "axes[1].grid(True, linestyle='-', linewidth=0.5)\n",
    "axes[1].set_xlabel(\"Frequency of the word direct\")\n",
    "axes[1].set_ylabel(\"Frequency of the word 857\")\n",
    "axes[1].set_title('Relationship between the frequencies of the words \"direct\" and \"857\" by Spam label')\n",
    "axes[1].legend(title='Spam Label', labels=['Not Spam', 'Spam'])\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273e6db0-23b6-4599-aa8a-83b19a090b85",
   "metadata": {},
   "source": [
    "Usually spam emails tend to have long sequences of capital letters and words in their content to catch attention.\n",
    "So I went to explore that, and created another histogram to reveal the relationship between spam emails and average capital run length, and as expected, the average capital run length is generally higher in spam email compared to non-spam emails.\n",
    "At first I only created one histogram, but then I decided to show the difference on 4 different scales based on the Average number of capital run, because there was some outliers, but even on the 0-50/0-100-0-200 scales, it is always the spam emails who have a higher average capital run length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b5d81-3d5b-448e-8d5b-4365276d8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(18, 6))  \n",
    "\n",
    "sns.scatterplot(\n",
    "    # I used jitter as is_spam is boolean so all points will have the same value (either spam or not spam), the plot would look like a straight line,\n",
    "    # so jittering would spread the points to have a better representation in the plot\n",
    "    x=np.random.normal(df['is_spam'], 0.05), \n",
    "    y=df['capital_run_length_average'],\n",
    "    hue=df['is_spam'],\n",
    "    alpha=0.6,    \n",
    "    ax=axes[0,0],\n",
    "    legend=False\n",
    "\n",
    "\n",
    ")\n",
    "axes[0,0].grid(True, linestyle='-', linewidth=0.5)\n",
    "axes[0,0].set_xticks([0,1],['Not spam','Spam'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=np.random.normal(df['is_spam'], 0.05), \n",
    "    y=df['capital_run_length_average'],\n",
    "    hue=df['is_spam'],\n",
    "    alpha=0.6,    \n",
    "    ax=axes[0,1],\n",
    "    legend=False\n",
    "\n",
    ")\n",
    "axes[0,1].grid(True, linestyle='-', linewidth=0.5)\n",
    "axes[0,1].set_xticks([0,1],['Not spam','Spam'])\n",
    "axes[0,1].set_ylabel(\"Average Capital Run Length (0-200)\")\n",
    "axes[0,1].set_ylim(0,200)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=np.random.normal(df['is_spam'], 0.05), \n",
    "    y=df['capital_run_length_average'],\n",
    "    hue=df['is_spam'],\n",
    "    alpha=0.6,    \n",
    "    ax=axes[1,0],\n",
    "    legend=False\n",
    "\n",
    "\n",
    ")\n",
    "axes[1,0].grid(True, linestyle='-', linewidth=0.5)\n",
    "axes[1,0].set_xticks([0,1],['Not spam','Spam'])\n",
    "axes[1,0].set_ylabel(\"Average Capital Run Length (0-100)\")\n",
    "axes[1,0].set_ylim(0,100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=np.random.normal(df['is_spam'], 0.05), \n",
    "    y=df['capital_run_length_average'],\n",
    "    hue=df['is_spam'],\n",
    "    alpha=0.6,    \n",
    "    ax=axes[1,1],\n",
    "    legend=False\n",
    "\n",
    ")\n",
    "axes[1,1].grid(True, linestyle='-', linewidth=0.5)\n",
    "axes[1,1].set_xticks([0,1],['Not spam','Spam'])\n",
    "axes[1,1].set_ylabel(\"Average Capital Run Length (0-50)\")\n",
    "axes[1,1].set_ylim(0,50)\n",
    "\n",
    "fig.suptitle(\"Relation between Spam Emails and Average Capital Run Length on different scales\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccdf0cb-fb83-43af-9c9a-173883aa9369",
   "metadata": {},
   "source": [
    "The following summary table confirms the previous finding, and shows a full comparison between an average spam email and an average non spam email, where we see that spam emails have an average of 9.5 capital run length, compared to 2.3 capital run length, this feature will be highly important in identifying spam email in addition to many other features as well such as word_freq_free, word_freq_you, word_freq_your etc.. \n",
    "This will extremely helpful in the success of the model, since it's all based on probabilities, and the role of Machine learning is to find patterns linked to a certain variable, and in this case, without much effort we can easily spot that there are certain patterns linked to the type of email. Features like capital run length, frequency of certain words will play a massive role in identifying the type of email by the classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e009c239-db87-425f-81c7-0312700f7490",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_email = df.groupby(by = 'is_spam').mean()\n",
    "display(avg_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3bbe8a-ad7e-412c-971a-436028754d29",
   "metadata": {},
   "source": [
    "After that, I moved to check the distribution of my values, I created at first a boxplot of all features which was not a great idea as capital run lengths affected the scale, so I created a subset of my initial dataframe, that contains only frequencies words, i.e to have a general idea on how my values look like.\n",
    "The results were not really good and further handling needs to be done, there was many outliers in the data within most of the features. While these outliers are normal and part of the 'real world' data, I wouldn't be getting rid of them as much as I will be doing some transformation to the values using scaling and transformation techniques which will reduce the skewness of our dataset (Suresh, 2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c8545-2afa-4120-9678-983e283ab5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplot of all features\n",
    "df.iloc[:,0:57].boxplot(figsize=(20, 6), rot=90)\n",
    "plt.title('Boxplots of All the Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b8951-2a0f-4154-922f-240714d1dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplot of frequency features\n",
    "freq_df = df.iloc[:,0:54]\n",
    "freq_df.boxplot(figsize=(20, 6), rot=90)\n",
    "plt.title('Boxplots of All the Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edba8f0-d6e8-4bb9-9dab-8996a7342a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler  = RobustScaler()\n",
    "df_scaled = robust_scaler.fit_transform(df)\n",
    "df_scaled = pd.DataFrame(df_scaled, columns= df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af25e00-2761-46f0-88e3-2cdc83a43ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df = df_scaled.iloc[:,0:54]\n",
    "## Boxplot for the word frequencies features (float columns)\n",
    "freq_df.boxplot(figsize=(20, 6), rot=90)\n",
    "plt.title('Boxplots of All the features after scaling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f867c9-07db-4391-b235-7881b8526163",
   "metadata": {},
   "source": [
    "We can see that the values are now within a much better range, the outliers are still there, but with much less influence, and most of the values are within a readable range as shown in the previous plot, we only needed one boxplot for all the features instead of using 2 just like before scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4370a12-43ed-4605-bbb3-0c5b77f95491",
   "metadata": {},
   "source": [
    "Even though I've scaled the data earlier on, and showed the differences with plots, I will be doing it again later on to the training and tesing sets, This approach would avoid Data leakage, which is the exposure of information between test and training data as they must be independent. This usually happens in the preprocessing steps such as standardization and PCA.\n",
    "By doing standardization and PCA to the initial df, we would expose the model to the testing data, and the model will perform better in numbers, but this will result in overfitting and test results will be misleading (Rukshan Pramoditha, 2022)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa6067-26e2-4bbd-a3b0-f48da9827f36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Summary\n",
    "In the previous cells, I started by exploring the dataset at first, noticed some inconsistencies about it so:\n",
    "- I changed all the object data types into float\n",
    "- Removed all the missing and unwanted values (zero, '?' etc..)\n",
    "- Removed the Unnamed: 0 column due to its irrelevance\n",
    "These steps were necessary as part of cleaning the data, as there's no point in visualising or implementing a model with dirty data.\n",
    "\n",
    "Then I went more into the Exploratory Data Analysis, where I checked the distribution of the emails and noticed the very slight imbalance (60/40), explored the correlation heatmap and explored some of the most correlated features, identified multicollinearity. Then I compared the capital run length between spam and non spam-emails followed by a comparative summary table that outlines some keys characteristics that belong to spam emails such as longer capital run lengths, higher frequencies of certain wrods (free, you, your etc..) this finding is highly important when it comes to the distinction of the email type achieved by the algorithm.\n",
    "\n",
    "For the scaling, we will use RobustScaler, scaling is essential before doing PCA as it is sensitive to the variance of each feature, and since we have some variance in our features, it will disproportionately affect the principal components (Jha, 2024). The reason I chose RobustScaler is because StandardScaler and MinMaxScaler are quite sensitive to outliers, while RobustScaler handles outliers and skewness in a much better way by using the median instead of mean which helps regarding the outliers we have and scales based on the Interquartile range (75th quantile - 25th quantile)   (Nalcin, 2022).\n",
    "\n",
    "While scaling was shown here, further techniques would be applied within the modelling section to avoid the leakage as mentioned previously. However, we can see the effects of RobustScaler on the features already (from 0-thousands to 0-200). RobustScaler is known well to handle outliers because it uses median and interquartile range (75th quantile - 25th quantile) making it resilient to outliers, but it preserves them as well which we may need as some spam emails may have frequencies occuring too much which is so common (Nalcin, 2022). However, later on during my model selection and part of my trying to get the best performance, I went to explore log transformation and minmax scaler which did actually perform better than using RobustScaler. Even though I'm convinced with the choice of Robust Scaler as a first option, the difference in the results have made me change the scaling method.\n",
    "\n",
    "Also PCA was also applied after, because one of the models that I chose (KNN) is sensitive to high dimensionality and we had to reduce it in order to get the best of it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7637db-b7c8-4d38-9310-0bad85fd8f7c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731d0f7e-1cc8-4f0a-a90f-119523555d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='is_spam')\n",
    "y = df['is_spam']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863fb71a-3e2d-450f-a3cf-0f01da530901",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1b5a1-bc65-451c-9986-9b8266d76190",
   "metadata": {},
   "source": [
    "KNN is a distance-based algorithm that classifies samples based on the majority class among their nearest neighbors. It's highly sensitive to feature scaling and outliers, in addition to high dimensionality which makes preprocessing crucial. It's suitable for spam detection when feature distributions are well-prepared so that is why I'm going to try several different techniques to make sure we get the best results from this algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bba8b4b-b35f-43fc-9478-153170f7156c",
   "metadata": {},
   "source": [
    "- V1: RobustScaler (Unstratified)\n",
    "- V2: RobustScaler + Tuning (Unstratified)\n",
    "- V3: Log Transformation + MinMaxScaler + Tuning (Unstratified)\n",
    "- V4: RobustScaler (Stratified)\n",
    "- V5: RobustScaler + Tuning (Stratified)\n",
    "- V6: Log Transformation + MinMaxScaler + Tuning (Stratified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb181493-3d4d-45ee-9ccf-96af1106e933",
   "metadata": {},
   "source": [
    "###  RobustScaler (Unstratified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73492482-fcda-495c-9891-70bcfa1d4ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data + robust scaler + PCA \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state= 11)\n",
    "\n",
    "robust_scaler  = RobustScaler()\n",
    "X_train = robust_scaler.fit_transform(X_train)\n",
    "# We don't fit on the test set, as it would take new median and IQR and cause data leakage\n",
    "# Source: https://scikit-learn.org/stable/common_pitfalls.html#how-to-avoid-data-leakage\n",
    "X_test = robust_scaler.transform(X_test) \n",
    "\n",
    "#source: https://builtin.com/machine-learning/pca-in-python\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "print(\"Number of PCA Components: \", pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd57c35-d063-4000-8fce-3f33e7ce9bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default KNN (k=5)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1708f-02f5-457d-9517-6d93c4861589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting results and displaying confusion matrix with classification report\n",
    "y_pred = knn.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1307d1-4f88-4724-90b6-28571532f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the main evaluation metrics for a summary table later on\n",
    "results = []\n",
    "# List of results, will be displayed in the summary\n",
    "\n",
    "results.append({\n",
    "    'Variant': 'RobustScaler (Unstratified)',\n",
    "    'Precision': round(precision_score(y_test, y_pred), 2),\n",
    "    'Accuracy': round(accuracy_score(y_test, y_pred),2),\n",
    "    'Recall': round(recall_score(y_test, y_pred),2),\n",
    "    'F1': round(f1_score(y_test, y_pred),2)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a932a1a-9286-4d8b-93f8-d9bbc50e3563",
   "metadata": {},
   "source": [
    "### RobustScaler + Tuning (Unstratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f61dd2-c4e9-42ee-8431-681dbd718acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefining the variables, for a cleaner code + when running all cells\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state= 11)\n",
    "X_train = robust_scaler.fit_transform(X_train)\n",
    "X_test = robust_scaler.transform(X_test)\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f3678-32f7-4903-9035-0c55558d9d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "# source: https://www.linkedin.com/pulse/improve-model-hyperparameter-tuning-k-nearest-muctary-abdallah-1e\n",
    "param_grid = {'n_neighbors': np.arange(1, 21),\n",
    "              'weights': ['uniform', 'distance', None],\n",
    "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'p': [1, 2]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b2337-671d-4be7-bc72-36a58a09aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search with KNN parameters\n",
    "grid = GridSearchCV(knn,param_grid,cv=5,scoring='f1')\n",
    "# train the grid \n",
    "grid.fit(X_train, y_train)\n",
    "# print the best parameters\n",
    "print(\"Best Hyperparameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbc5d8f-d13a-4f01-8531-7fc52362cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the best hyperparameters to the knn instance \n",
    "best_knn = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d5a7d7-a867-4dbc-8749-cafe15cdc300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with best hyperparameters\n",
    "best_knn.fit(X_train, y_train)\n",
    "y_pred = best_knn.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb2482-4b0f-4eef-8260-aa2746ba7e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\n",
    "    'Variant': 'RobustScaler + Tuning (Unstratified)',\n",
    "    'Precision': round(precision_score(y_test, y_pred), 2),\n",
    "    'Accuracy': round(accuracy_score(y_test, y_pred),2),\n",
    "    'Recall': round(recall_score(y_test, y_pred),2),\n",
    "    'F1': round(f1_score(y_test, y_pred),2)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33441afd-6bad-4890-92f6-69757149630c",
   "metadata": {},
   "source": [
    "### Log Transformation + MinMaxScaler (Unstratified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb24b71-0fec-4999-8a95-05b68b344e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state= 11) \n",
    "\n",
    "# log(1+x), we have some 0's, so we use log(1+x) instead.\n",
    "X_train  = np.log1p(X_train)\n",
    "X_test  = np.log1p(X_test)\n",
    "\n",
    "# Minmax scaling\n",
    "minmax = MinMaxScaler()\n",
    "X_train = minmax.fit_transform(X_train)\n",
    "X_test = minmax.transform(X_test) \n",
    "\n",
    "pca = PCA(n_components=0.95) # pca 95% of the variance\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "pca.n_components_ # number of the pca components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a90b55e-f676-43e6-ad3d-75bfd59cf194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search with KNN parameters\n",
    "grid = GridSearchCV(knn,param_grid,cv=5,scoring='f1')\n",
    "# train the grid \n",
    "grid.fit(X_train, y_train)\n",
    "# print the best parameters\n",
    "print(\"Best Hyperparameters:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e266c-48f9-47de-967d-466592089568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the best hyperparameters to the knn instance \n",
    "best_knn = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd7e063-2b9c-45e8-85b6-d7e45fbe72c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with best hyperparameters\n",
    "best_knn.fit(X_train, y_train)\n",
    "y_pred = best_knn.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc317f-70c7-448d-839d-2f4d36552d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\n",
    "    'Variant': 'Log Transformation + MinMaxScaler (Unstratified)',\n",
    "    'Precision': round(precision_score(y_test, y_pred), 2),\n",
    "    'Accuracy': round(accuracy_score(y_test, y_pred),2),\n",
    "    'Recall': round(recall_score(y_test, y_pred),2),\n",
    "    'F1': round(f1_score(y_test, y_pred),2)\n",
    "})\n",
    "print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3dad4c-2e7f-4b40-a381-45f48064c109",
   "metadata": {},
   "source": [
    "###  Default KNN Classifier (stratified split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769feb82-7291-40ce-a1d3-82331f61bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state= 11,stratify=y)\n",
    "\n",
    "X_train = robust_scaler.fit_transform(X_train)\n",
    "X_test = robust_scaler.transform(X_test) \n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "print(\"Number of PCA Components: \", pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b972f8dd-f8ae-420c-b7d7-9fd7f31d51bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default KNN (k=5)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a2cd4-9d69-41f4-bc81-173813a2b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e3ae33-a4d1-4475-8df3-9a47d094d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\n",
    "    'Variant': 'RobustScaler (Stratified)',\n",
    "    'Precision': round(precision_score(y_test, y_pred), 2),\n",
    "    'Accuracy': round(accuracy_score(y_test, y_pred),2),\n",
    "    'Recall': round(recall_score(y_test, y_pred),2),\n",
    "    'F1': round(f1_score(y_test, y_pred),2)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c9a39a-6180-409f-990d-7ea3110372d3",
   "metadata": {},
   "source": [
    "###  KNN Classifier after hyperparameter tuning (stratified split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3cdc28-841c-4e58-b017-3076ef2c3966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search with KNN parameters\n",
    "grid = GridSearchCV(knn,param_grid,cv=5,scoring='f1')\n",
    "# train the grid \n",
    "grid.fit(X_train, y_train)\n",
    "# print the best parameters\n",
    "print(\"Best Hyperparameters:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89feba30-0374-46d4-bada-119b629af58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the best hyperparameters to the knn instance \n",
    "best_knn = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875068ab-a210-43fb-94ac-a2529f5ce494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with best hyperparameters\n",
    "best_knn.fit(X_train, y_train)\n",
    "y_pred = best_knn.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d738369-e3ff-4e41-ade7-4cfde5bdcca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\n",
    "    'Variant': 'KNN Classifier after hyperparameter tuning (stratified split)',\n",
    "    'Precision': round(precision_score(y_test, y_pred), 2),\n",
    "    'Accuracy': round(accuracy_score(y_test, y_pred),2),\n",
    "    'Recall': round(recall_score(y_test, y_pred),2),\n",
    "    'F1': round(f1_score(y_test, y_pred),2)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0a3f8b-4640-429f-9ba3-39d224d442e3",
   "metadata": {},
   "source": [
    "### KNN Classifier with log transformation and MinMax Scaler (stratified split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace7ad2-71c6-4ea9-ae41-9f2cf38f6e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state= 11, stratify=y) # Splitting data\n",
    "\n",
    "X_train  = np.log1p(X_train)\n",
    "X_test  = np.log1p(X_test)\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "X_train = minmax.fit_transform(X_train) # minmax scaling\n",
    "X_test = minmax.transform(X_test) \n",
    "\n",
    "pca = PCA(n_components=0.95) # pca 95% of the variance\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "print(\"Number of PCA Components: \", pca.n_components_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9ab64c-c85c-4bdd-b3c0-914af2579c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search with KNN parameters\n",
    "grid = GridSearchCV(knn,param_grid,cv=5,scoring='f1')\n",
    "# train the grid \n",
    "grid.fit(X_train, y_train)\n",
    "# print the best parameters\n",
    "print(\"Best Hyperparameters:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865e5797-7f43-4304-8eb4-402dd2320d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the best hyperparameters to the knn instance \n",
    "best_knn = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d61ae9b-f633-40d1-99b6-93294f8914a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with best hyperparameters\n",
    "best_knn.fit(X_train, y_train)\n",
    "y_pred = best_knn.predict(X_test)\n",
    "cm_knn = confusion_matrix(y_test, y_pred)\n",
    "print(cm_knn)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29436737-7e14-49b9-b3b0-e7c17666d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\n",
    "    'Variant': 'KNN Classifier with log transformation and MinMax Scaler (stratified split)',\n",
    "    'Precision': round(precision_score(y_test, y_pred), 2),\n",
    "    'Accuracy': round(accuracy_score(y_test, y_pred),2),\n",
    "    'Recall': round(recall_score(y_test, y_pred),2),\n",
    "    'F1': round(f1_score(y_test, y_pred),2)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f6d1c8-84b8-403e-98bb-c8852511f0be",
   "metadata": {},
   "source": [
    "### KNN Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bbd787-ad76-4515-9d1b-8998ef6e2c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None) \n",
    "results = pd.DataFrame(results)\n",
    "results=results.sort_values(by='F1',ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ec8433-2a65-468d-88f6-6799f9d03892",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "I had skewness in my data, in addition to high dimensionality, it was necessary to use PCA for the dimensionality reduction where I chose to keep 95% to reduce some of the noise without loosing too much information. For the choice of scaling, I started with Robust scaler at first and tuned the model, I was happy with the results until I moved to the naive bayes where I had to use minmax, so I decided to go back and try minmax scaling with log1p transformation to normalize the data.\n",
    "I did these preprocessing strategies without stratifying the data at first, then I wanted to explore how the models would behave if I maintain the ratio of my target variable balance, remember we had 60/40, I wanted to see if we preserve that in the splits, how would our model behave.\n",
    "\n",
    "After testing six KNN variants with different preprocessing, tuning, and splitting strategies, the best-performing model used:\n",
    "- **log1p transformation**\n",
    "- **MinMaxScaler**\n",
    "- **Stratified split**\n",
    "- **Hyperparameters: k=14, weights='distance' (other params are default)**\n",
    "\n",
    "This configuration achieved the highest F1 score of 0.93, reflecting a strong balance between Precision (0.95) and recall (0.92) for the positive (spam) class.\n",
    "\n",
    "The confusion matrix confirmed solid performance:\n",
    "- 18 False Positives (non-spam misclassified as spam)\n",
    "- 29 False Negatives (spam misclassified as non-spam)\n",
    "\n",
    "##### Overall, the preprocessing techniques with the tuning were fruitful as they increased initial accuracy from 90% to 95% and more importantly, we significantly reduced:\n",
    "##### - False Positives: from 40 → 18\n",
    "##### - False Negatives: from 48 → 29\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf16270b-f90c-4d75-9e08-20c27ea26c60",
   "metadata": {},
   "source": [
    "## Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c5c783-917e-4bd0-8eeb-083280cb883d",
   "metadata": {},
   "source": [
    "Naive Bayes algorithms are so good choice when it comes to spam detection. However, they are so limited when it comes to optimisation.\n",
    "Unlike what we did with KNN, where we tuned the paramaters, we don't have the same amount of freedom when it comes to naive bayes.\n",
    "That is why it is so important to choose the right variant, and since our values do not follow a gaussian distribution (normal distribution), and we are looking at table of words' frequencies. Multinomial Naive Bayes would be the chosen variant.\n",
    "\n",
    "However, there must be some changes to our data preparation:\n",
    "- MultinomialNB cannot have negative values, which has happened during scaling with robust scaler, so instead we will use MinMaxScaler that will make sure our values are ranged between 0 and 1.\n",
    "- PCA would also affect the values ranges as well and may change some to negative, and also we need dimensionality for the MultinomialNB, so we won't be applying PCA in this specific algorithm.\n",
    "\n",
    "Unlike KNN, MultinomialNB doesn't have many paramaters to change, and changing the values doesn't affect much, so I will be trying to optimise the results by exploring different preprocessing techniques only:\n",
    "- MinMax scaler only (Unstratified)\n",
    "- log transformation + MinMax Scaler (Unstratified)\n",
    "- MinMax scaler only (stratified data)\n",
    "- log transformation + MinMax Scaler (stratified data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e912ca-333a-4373-96cb-cb0a107480b6",
   "metadata": {},
   "source": [
    "### MinMax scaler only (Unstratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1906b9c-125f-4586-a809-469a211997d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state= 11) # Splitting data\n",
    "minmax = MinMaxScaler()\n",
    "X_train = minmax.fit_transform(X_train)\n",
    "X_test = minmax.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2154d-deaa-4c79-ab61-09a26b84a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB() \n",
    "mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0219a6c9-7acc-4fcd-a4bf-131b8cf69f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = mnb.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c8249-f6d8-4558-982c-cebd307885bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a0196-b334-436f-8b0e-ab1c4887df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the main evaluation metrics for a summary table later on\n",
    "results = []\n",
    "# List of results, will be displayed in the summary\n",
    "\n",
    "results.append({\n",
    "    'Variant': 'MinMax scaler only (Unstratified)',\n",
    "    'Precision': round(precision_score(y_test, y_pred), 2),\n",
    "    'Accuracy': round(accuracy_score(y_test, y_pred),2),\n",
    "    'Recall': round(recall_score(y_test, y_pred),2),\n",
    "    'F1': round(f1_score(y_test, y_pred),2)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f40b49e-8092-4ad8-a7e4-586913db9a2e",
   "metadata": {},
   "source": [
    "### log transformation + MinMax Scaler (Unstratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f5edff-a2f9-42d6-bb9a-ae24e06cefee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state= 11) # Splitting data\n",
    "X_train  = np.log1p(X_train)\n",
    "X_test  = np.log1p(X_test)\n",
    "X_train = minmax.fit_transform(X_train)\n",
    "X_test = minmax.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fa5614-80e4-4a92-85ff-0530fb704902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = mnb.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4621af7b-c429-4002-bc68-4ff36bbe3e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e40a529-23db-4d5f-a121-5f3cb823baab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\n",
    "    'Variant': 'log transformation + MinMax Scaler (Unstratified)',\n",
    "    'Precision': round(precision_score(y_test, y_pred), 2),\n",
    "    'Accuracy': round(accuracy_score(y_test, y_pred),2),\n",
    "    'Recall': round(recall_score(y_test, y_pred),2),\n",
    "    'F1': round(f1_score(y_test, y_pred),2)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56646355-2e49-4ac3-bbd8-d783d98a0c4c",
   "metadata": {},
   "source": [
    "### MinMax scaler only (stratified data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654cb442-678c-46be-8516-5dfd9f858ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state= 11, stratify=y) # Splitting data\n",
    "X_train = minmax.fit_transform(X_train)\n",
    "X_test = minmax.transform(X_test) \n",
    "\n",
    "mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab93037-da1e-4b0a-b747-5c5b2a92c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = mnb.predict(X_test)\n",
    "cm_mnb =confusion_matrix(y_test, y_pred)\n",
    "print(cm_mnb)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb126b7-f35c-4030-8a8a-86e9b7d3d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\n",
    "    'Variant': 'MinMax scaler only (stratified)',\n",
    "    'Precision': round(precision_score(y_test, y_pred), 2),\n",
    "    'Accuracy': round(accuracy_score(y_test, y_pred),2),\n",
    "    'Recall': round(recall_score(y_test, y_pred),2),\n",
    "    'F1': round(f1_score(y_test, y_pred),2)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d507c-e48b-4d8f-8517-9d7ea7b07e49",
   "metadata": {},
   "source": [
    "### log transformation + MinMax Scaler (stratified data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7547f99b-c300-48ec-ae4f-0b0e46e44019",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state= 11, stratify=y) \n",
    "X_train  = np.log1p(X_train)\n",
    "X_test  = np.log1p(X_test)\n",
    "X_train = minmax.fit_transform(X_train)\n",
    "X_test = minmax.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da633621-a570-4dfa-a424-509c36ab45d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = mnb.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6328035-9d9c-4a87-861f-3573c21be911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the main evaluation metrics for a summary table later on\n",
    "# List of results, will be displayed in the summary\n",
    "\n",
    "results.append({\n",
    "    'Variant': 'log transformation + MinMax Scaler (stratified data)',\n",
    "    'Precision': round(precision_score(y_test, y_pred), 2),\n",
    "    'Accuracy': round(accuracy_score(y_test, y_pred),2),\n",
    "    'Recall': round(recall_score(y_test, y_pred),2),\n",
    "    'F1': round(f1_score(y_test, y_pred),2)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7994b2-648b-45c2-9967-ecec6a09fb21",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7e345a-3e13-41c1-82b3-3b2caa686f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results = results.sort_values(by='F1',ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bcb9d4-e6b5-40fb-913e-86c546362ddd",
   "metadata": {},
   "source": [
    "Four Naive Bayes variants were tested, all using MinMaxScaler due to MultinomialNB's requirement for non-negative input. PCA was not used, as it can produce negative values and reduce meaning from features which affects the algorithm. Although hyperparameter tuning was not used as I believe it wouldn't be fruitful in this case, however preprocessing techniques made a small difference.\n",
    "\n",
    "Among the tested variants, the best results were achieved using **MinMaxScaler with a stratified split**, where we got 0.88 F1 score while balancing the precision (0.96) and the recall (0.8), this model is so good at minimizing the False Positives (non-spam misclassified as spam), only 11, which is quite important in this context, as we don't want to have important emails hanging in the spam folder. \n",
    "However, the number of False Negatives (spam misclassified as non-spam) was 71 which is quite concerning as the model did not achieve well in its main mission, detecting spam.\n",
    "\n",
    "Interestingly, the log transformation did not work well like it did in the KNN, and made the results much worse as precision went down to 0.76-0.77 despite improving recall which can be due to the changes in the values representing frequencies mainly where they lost some meaning after transformation and scaling, so scaling looks enough in this case.\n",
    "\n",
    "Stratification clearly improved performance overall, especially when compared to unstratified versions, further reinforcing its value in maintaining class balance for this dataset.\n",
    "\n",
    "In conclusion, the best-performing Naive Bayes configuration was MinMaxScaler only + Stratified Split, which maintained a strong balance between accuracy, recall, and precision for the spam class.\n",
    "\n",
    "Overall, we managed to get a reasonable results, but the number of False Negatives was relatively high for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1f5fa1-f8f8-4d3f-a9c4-f31af6a9686d",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653f059-a1cd-43f3-95a6-fc13197fba72",
   "metadata": {},
   "source": [
    "Based on the findings of the EDA, such as the slight imbalance (60/40), the mulitcolinearity and the high dimensioanality, in addition to the outliers, I was aiming to go for a Tree based algorithm that would be able to handle these changes without any issues.\n",
    "The choice to go for Random Forest directly instead of exploring a decision \n",
    "\n",
    "Random Forest was selected as it naturally handles multicollinearity, is resistant to outliers, and does not require feature scaling or transformation. It also performs well on high-dimensional data (57 is relatively high) , making it a strong option for spam classification in this context.\n",
    "\n",
    "Since model interpretability and training time were not priorities in this project for me, and the goal was to compare classification performance across different approaches, Random Forest was selected as a stronger alternative that typically generalizes better than a single Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b78d69-429c-4e71-8797-006ec2931e66",
   "metadata": {},
   "source": [
    "### Default Random Forest (Unstratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cacd8c9-199f-45fa-af4d-bd07b58b04c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state= 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ec425c-cc16-477c-a632-e761e7c83897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default params\n",
    "rf = RandomForestClassifier(random_state=11)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9176c63c-a036-4633-9e8a-8398112b3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing default parameters\n",
    "print(rf.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf59e9-4c2a-4a35-894f-61a04474b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e188632-d5b9-4ae8-86ad-cb2cfd27454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfe7b93-3507-4752-8a5c-aa6019c854c6",
   "metadata": {},
   "source": [
    "Notice that there is overfitting, training accuracy is almost 100%, while testing accuracy is 96%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ab0ce-7bf5-4fa1-a428-212a7936373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Accuracy:\", accuracy_score(y_train, rf.predict(X_train)))\n",
    "print(\"Training Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f90cb-9386-46f5-bbac-0c9b35d94b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the main evaluation metrics for a summary table later on\n",
    "results = []\n",
    "# List of results, will be displayed in the summary\n",
    "\n",
    "results.append({\n",
    "    'Variant': 'Default Random Forest',\n",
    "    'Precision': round(precision_score(y_test, y_pred), 2),\n",
    "    'Accuracy': round(accuracy_score(y_test, y_pred),2),\n",
    "    'Recall': round(recall_score(y_test, y_pred),2),\n",
    "    'F1': round(f1_score(y_test, y_pred),2)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4e28ef-552c-4ada-9496-835dc1663a06",
   "metadata": {},
   "source": [
    "### Random Forest with hyperparameter tuning (Unstratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca47aa99-bef4-4b9c-a024-7a16e1cddfbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Source: https://medium.com/@kalpit.sharma/mastering-random-forest-hyperparameter-tuning-for-enhanced-machine-learning-models-2d1a8c6c426f\n",
    "\n",
    "n_estimators = [200,400,600,1000] # Number of trees in the forest\n",
    "max_features = ['log2', 'sqrt'] # Number of features to consider at every split\n",
    "max_depth = [None,10,30,50,70] # Maximum number of levels in tree\n",
    "min_samples_split = [2, 5] # Minimum number of samples required to split a node\n",
    "min_samples_leaf = [1, 2] # Minimum number of samples required at each leaf node\n",
    "bootstrap = [False] # Method of selecting samples for training each tree\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'bootstrap': bootstrap,\n",
    "}\n",
    "\n",
    "print(param_grid)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=11)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid, \n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30de296-b17e-4948-b2fb-a9e9ac3e5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best combination of parameters\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a531f538-fcae-4b02-84b0-eb577efe1106",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = grid_search.best_estimator_\n",
    "# train the model with best hyperparameters\n",
    "best_rf.fit(X_train, y_train)\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "cm_rf= confusion_matrix(y_test, y_pred)\n",
    "print(cm_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59971b-9abb-487c-a769-c6e169c985cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a295e-41ec-4012-bd3a-203961bc771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Will need this in the model selection part\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, best_rf.predict(X_train)))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80825084-ae2a-4f7d-bc4d-067b5d2dc4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of results, will be displayed in the summary\n",
    "\n",
    "results.append({\n",
    "    'Variant': 'Random Forest with hyperparameter tuning (Unstratified)',\n",
    "    'Precision': round(precision_score(y_test, y_pred), 2),\n",
    "    'Accuracy': round(accuracy_score(y_test, y_pred),2),\n",
    "    'Recall': round(recall_score(y_test, y_pred),2),\n",
    "    'F1': round(f1_score(y_test, y_pred),2)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f0eb93-2e3e-455a-bd0b-7289cae4ed1c",
   "metadata": {},
   "source": [
    "### Default Random Forest (stratified split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f543a5c-39e5-45dc-9075-2cc08e531a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state= 11,stratify=y)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred= rf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e3c0c0-4b51-4c9f-ad52-e231021c3828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of results, will be displayed in the summary\n",
    "\n",
    "results.append({\n",
    "    'Variant': 'Default Random Forest (stratified split)',\n",
    "    'Precision': round(precision_score(y_test, y_pred), 2),\n",
    "    'Accuracy': round(accuracy_score(y_test, y_pred),2),\n",
    "    'Recall': round(recall_score(y_test, y_pred),2),\n",
    "    'F1': round(f1_score(y_test, y_pred),2)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16797c0-15a7-4c66-9644-5b9a96a2f233",
   "metadata": {},
   "source": [
    "### Random Forest with Hyperparameter tuning (stratified split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f473b37f-0af7-4f6e-a5bc-bf0a8f81c56e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba477bb-32e0-4bdd-a133-887844eeecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0402117-f428-4363-922d-6bfb7da8762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "best_rf= best_rf.fit(X_train, y_train)\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59029f94-c60d-432b-ba34-04a9af1a9b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of results, will be displayed in the summary\n",
    "\n",
    "results.append({\n",
    "    'Variant': 'Random Forest with Hyperparameter tuning (stratified split)',\n",
    "    'Precision': round(precision_score(y_test, y_pred), 2),\n",
    "    'Accuracy': round(accuracy_score(y_test, y_pred),2),\n",
    "    'Recall': round(recall_score(y_test, y_pred),2),\n",
    "    'F1': round(f1_score(y_test, y_pred),2)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c2571e-96bb-42da-8a83-4cbe3aa73a62",
   "metadata": {},
   "source": [
    "### Random Forest Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ab5a0-7f98-477b-b58b-1d1802966508",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results = results.sort_values(by='F1',ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e950d0-41bf-4226-a2a2-f2010e18f3e4",
   "metadata": {},
   "source": [
    "Random Forest was evaluated using four variants to assess the impact of both stratified data splitting and hyperparameter tuning. No preprocessing was applied, as Random Forest handles outliers, multicollinearity, and different feature scales (frequency feature and capital run features).\n",
    "\n",
    "The best-performing variant in terms of F1-score was **Random Forest with hyperparameter tuning (Unstratified)**, which achieved an F1-score of **0.96**, with equally strong precision and recall (0.95 and 0.96 respectively). Interestingly, although stratification improved performance in earlier models like KNN and MNB, it did not result in significant gains here — and in fact, the stratified tuned model had slightly lower recall (0.93) and F1-score (0.95).\n",
    "The successful hyperparamaters combination was:\n",
    "- n_estimators: 1000\n",
    "- max_depth: 30\n",
    "- max_features: log2\n",
    "- min_samples_leaf: 1 (default)\n",
    "- min_samples_split: 2 (default)\n",
    "- bootstrap: False\n",
    "\n",
    "\n",
    "The confusion matrix of the best-performing model confirms its robustness:  \n",
    "- **False Negatives (Spam missed):** 15  \n",
    "- **False Positives (Non-spam misclassified):** 18  \n",
    "\n",
    "This balance between false positives and false negatives highlights the effectiveness of the tuned model in minimizing both kinds of misclassification which is key in our case. However, if we want False Positives, the tuned stratified RF has 14 False Positives.\n",
    "\n",
    "Overall, Random Forest provided the strongest performance overall with minimal preprocessing, and the unstratified tuned model emerged as the top performer among all tested configurations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c88c41-2ed8-40a1-92fb-b6301a17a3e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Final Classification Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e68b34-20c3-4686-9d18-897403f3caec",
   "metadata": {},
   "source": [
    "The final classification model selected was **Random Forest with hyperparameter Tuning (Unstratified)** being the one with the best performance and balance between precision and recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50d052-4001-4f08-a66c-303ba13cfd7c",
   "metadata": {},
   "source": [
    "**Final Metrics on Test Set:**\n",
    "- **Training Accuracy:** 1.00\n",
    "- **Testing Accuracy:** 0.96\n",
    "- **Precision:** 0.95\n",
    "- **Recall:** 0.96\n",
    "- **F1-Score:** 0.96\n",
    "- \n",
    "The accuracy and F1-score on the **training set** were  1.0, while performance on the **test set** remained at 0.96. This minimal gap suggests that the model generalizes well but there is still a very slight overfitting. This can be due to the high number of trees selected by the grid search (1000), and even the depth of trees as well (30) compared to the size of data. I tried many combinations within my paramater grid, most of them gave very similar results.\n",
    "I managed to slightly improve the base random forest performance (reduced the False negatives from 21 to 18), but I did not manage to reduce the overfitting or massively increase accuracy that only increased from 96% to 96.4% which is quite low.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d817d44f-cb5c-4083-92f5-07567eb8dfd0",
   "metadata": {},
   "source": [
    "The figure below compares the confusion matrices of the best-performing variant from each model. Random Forest not only achieved the highest overall F1-score, but also produced the **fewest false negatives (15)** which shows good detection of spam emails, MultinomialNB, was so good at reducing the **False Positives (11)**, but it missed 71 spam emails. KNN was similar to Random Fores in false negatives (18), performing fairly well, but missed more spam emails (29) than Random Forest (15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6cfb05-df02-437c-9183-1787be2b401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Define class labels\n",
    "labels = ['Not Spam', 'Spam']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# KNN\n",
    "sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Blues', ax=axes[0], xticklabels=labels, yticklabels=labels)\n",
    "axes[0].set_title(\"KNN\")\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "sns.heatmap(cm_mnb, annot=True, fmt='d', cmap='Greens', ax=axes[1], xticklabels=labels, yticklabels=labels)\n",
    "axes[1].set_title(\"Multinomial Naive Bayes\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "\n",
    "# Random Forest\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Oranges', ax=axes[2], xticklabels=labels, yticklabels=labels)\n",
    "axes[2].set_title(\"Random Forest\")\n",
    "axes[2].set_xlabel(\"Predicted\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Confusion Matrices – Top Model Variants\", fontsize=16, y=1.05)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf2892-19c9-4acf-b637-ad33eaec5818",
   "metadata": {},
   "source": [
    "**Conclusion:**  \n",
    "In spam classification and detection, I believe that balancing the spam identification and reducing the misclassification of non spam emails as spam is highly important, that is why I only focused on False Positives and False Negatives. For this reason I chose **Random Forest with Hyperparameter Tuning (Unstratified)** as the final model. While not perfect and I wouldn't trust it with emails, there may be other algorithms that can be tried which may give better results. The model provided the most reliable and balanced performance among all tested classifiersas shown in the previous matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47993bea-3dbc-4201-bc76-7236d9587496",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# References:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a948a6ae-1579-4df1-9db3-ce5c6a260fce",
   "metadata": {},
   "source": [
    "- mmalinda (2020). Testing recommendations for binary classification with an imbalanced target variable. [online] Medium. Available at: https://medium.com/@mmalinda/testing-recommendations-for-binary-classification-with-an-imbalanced-target-variable-ff8b120ea8c9.\n",
    "\n",
    "- Suresh, A. (2020). How to Remove Outliers for Machine Learning? [online] Analytics Vidhya. Available at: https://medium.com/analytics-vidhya/how-to-remove-outliers-for-machine-learning-24620c4657e8.\n",
    "\n",
    "- Mustafa Erboga, Ph.D (2024). Multicollinearity in Data Science and Machine Learning: The Hidden Threat and How to Tackle It. [online] Medium. Available at: https://medium.com/academy-team/multicollinearity-in-data-science-and-machine-learning-the-hidden-threat-and-how-to-tackle-it-28e5800dcf4d.\n",
    "\n",
    "- ‌Nalcin, S. (2022). StandardScaler vs. MinMaxScaler vs. RobustScaler: Which one to use for your next ML project? [online] Medium. Available at: https://medium.com/@onersarpnalcin/standardscaler-vs-minmaxscaler-vs-robustscaler-which-one-to-use-for-your-next-ml-project-ae5b44f571b9.\n",
    "\n",
    "- ‌Rukshan Pramoditha (2022). How to Avoid Data Leakage in Data Preprocessing - Data Science 365 - Medium. [online] Medium. Available at: https://medium.com/data-science-365/how-to-avoid-data-leakage-in-data-preprocessing-f2d0357979eb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b49daa-c9e2-43a9-820a-32405772a87d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310 - TensorFlow)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
